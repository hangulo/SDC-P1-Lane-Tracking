{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "\n",
    "## Project \\#1: **Finding Lane Lines on the Road**    \n",
    "(built by Hector Angulo May 2017)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale(img):\n",
    "    \"\"\"Applies the Grayscale transform\n",
    "    This will return an image with only one color channel\n",
    "    but NOTE: to see the returned image as grayscale\n",
    "    (assuming your grayscaled image is called 'gray')\n",
    "    you should call plt.imshow(gray, cmap='gray')\"\"\"\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Or use BGR2GRAY if you read an image with cv2.imread()\n",
    "    # return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    \"\"\"Applies the Canny transform\"\"\"\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=10):\n",
    "    left_slopes = []\n",
    "    right_slopes = []\n",
    "    left_coordinates = []\n",
    "    right_coordinates = []\n",
    "    min_y  =image.shape[0]  # Want to find the farthest point away from car to have both lines have same length.\n",
    "\n",
    "    \n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            slope = ((y2-y1)/(x2-x1))\n",
    "\n",
    "            ## Lets group into left and right lane\n",
    "            if slope > .1 and slope < 100:   # Right lane since image is inverted\n",
    "                gr_slopes.append(slope)\n",
    "                right_coordinates.append([x1,y1])\n",
    "                right_coordinates.append([x2,y2])\n",
    "              \n",
    "            elif slope < -.1 and slope > -100:  #Left lane\n",
    "                gl_slopes.append(slope)\n",
    "                left_coordinates.append([x1,y1])\n",
    "                left_coordinates.append([x2,y2])\n",
    "                \n",
    "            else: \n",
    "                print(\"### Too close to horizontal or  vertical line. Removing from group ####\")\n",
    "                           \n",
    "    # TODO: This is very inneficient memory-wise, dont need ALL the entries since list gets into thousands after\n",
    "    ## just a few seconds of video, a rolling average is enough. But this proves we can smooth out lines with \n",
    "    ## global memory\n",
    "    \n",
    "    average_left = sum(gl_slopes)/ len(gl_slopes)\n",
    "    average_right = sum(gr_slopes)/ len(gr_slopes)\n",
    "    \n",
    "    print(len(gr_slopes))\n",
    "\n",
    "    # Sort the coordinates to better find the leftmost and rightmost points (i.e extreme of lines)\n",
    "    # Got this sorting tip off of Stackoverflow.  Dont fully understand the 'lambda' context but seems its a way to\n",
    "    # define HOW you want things sorted and here I'm saying sort by X coordinate first, then Y.\n",
    "    sorted_left = sorted(left_coordinates , key=lambda k: [k[0], k[1]])  \n",
    "    sorted_right = sorted(right_coordinates , key=lambda k: [k[0], k[1]])\n",
    "    \n",
    "    \n",
    "    # We will calculate the 'b' for each line and also find the extreme coordinates to create a new single line\n",
    "    left_b= sorted_left[0][1] - average_left*sorted_left[0][0]      # calculate b for left line\n",
    "    left_bottom_x = int((img.shape[0]-left_b)/average_left)\n",
    "    last_coordinate = len(sorted_left)-1  #find the  coordinate for the 'top' of left line\n",
    "    \n",
    "    right_b = sorted_right[0][1] - average_right*sorted_right[0][0] \n",
    "    right_bottom_x = int((img.shape[0]-right_b)/average_right)\n",
    "    \n",
    "    left_y = sorted_left[last_coordinate][1]\n",
    "    right_y = sorted_right[0][1]\n",
    "    min_y = min(left_y, right_y)\n",
    "    \n",
    "    left_top_x= int((min_y-left_b)/average_left)\n",
    "    right_top_x = int((min_y-right_b)/average_right)\n",
    "    \n",
    "    # Define the ends of both lines\n",
    "    bottom_left = (left_bottom_x, img.shape[0])\n",
    "    #top_left  = (left_top_x,min_y)   \n",
    "    ### older code\n",
    "    last_coordinate = len(sorted_left)-1  #find the  coordinate for the 'top' of left line\n",
    "    top_left  = (sorted_left[last_coordinate][0],sorted_left[last_coordinate][1])   \n",
    "    \n",
    "    bottom_right = (right_bottom_x, img.shape[0])\n",
    "    top_right = (sorted_right[0][0],min_y)     \n",
    "\n",
    "    #print(average_left, left_b, left_top_x, bottom_left, top_left)\n",
    "    \n",
    "    # Now draw the lines with all the info we have\n",
    "    cv2.line(img, bottom_left, top_left, color, thickness)   #Left line\n",
    "    \n",
    "    cv2.line(img, bottom_right, top_right, color, thickness)#Right line\n",
    "    \n",
    "    \n",
    "def draw_lines_orig(img, lines, color=[255, 0, 0], thickness=2):\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "\n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    \"\"\"\n",
    "    `img` should be the output of a Canny transform.\n",
    "        \n",
    "    Returns an image with hough lines drawn.\n",
    "    \"\"\"\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "    draw_lines(line_img, lines)\n",
    "    return line_img\n",
    "\n",
    "# Python 3 has support for cool math symbols.\n",
    "\n",
    "def weighted_img(img, initial_img, α=0.8, β=1., λ=0.):\n",
    "    \"\"\"\n",
    "    `img` is the output of the hough_lines(), An image with lines drawn on it.\n",
    "    Should be a blank image (all black) with lines drawn on it.\n",
    "    \n",
    "    `initial_img` should be the image before any processing.\n",
    "    \n",
    "    The result image is computed as follows:\n",
    "    \n",
    "    initial_img * α + img * β + λ\n",
    "    NOTE: initial_img and img must be the same shape!\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(initial_img, α, img, β, λ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lane Finding Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    gray = grayscale(image)\n",
    "    img_hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    \n",
    "    ##  Mask for only white and yellow lines\n",
    "    lower_yellow = np.array([20, 100, 100])\n",
    "    upper_yellow = np.array([30, 255, 255])\n",
    "    mask_yellow = cv2.inRange(img_hsv, lower_yellow, upper_yellow)\n",
    "    mask_white = cv2.inRange(gray, 200, 255)\n",
    "    mask_yw = cv2.bitwise_or(mask_white, mask_yellow)\n",
    "    mask_yw_image = cv2.bitwise_and(gray, mask_yw)\n",
    "                            \n",
    "    ## Blur to reduce noise before doing edge detection\n",
    "    gauss = cv2.GaussianBlur(mask_yw_image,(5,5), 0)\n",
    "\n",
    "    # Do Canny Edge Detection   \n",
    "    low_threshold = 50\n",
    "    high_threshold = 150\n",
    "    canny_edges = canny(gauss,low_threshold,high_threshold)\n",
    "\n",
    "    # Region of Interest\n",
    "    vertices = [np.array([[80,540],[465,315],[500,315],[900,540]], dtype=np.int32)]\n",
    "    ROI_masked = region_of_interest(canny_edges, vertices)\n",
    "\n",
    "    # Hough Transform\n",
    "    rho = 1\n",
    "    theta = np.pi/180\n",
    "    threshold = 20\n",
    "    min_line_len = 25\n",
    "    max_line_gap = 50\n",
    "    hough_image = hough_lines(ROI_masked, rho, theta, threshold, min_line_len, max_line_gap)\n",
    "\n",
    "    # Apply the lines to the original image\n",
    "    weighted_image = weighted_img(hough_image, image, α=.8, β=1., λ=0.)\n",
    "    \n",
    "    return weighted_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test it on an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_left, left_b, left_top_x, bottom_left, top_left\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'gr_slopes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-c97626e26d16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"average_left, left_b, left_top_x, bottom_left, top_left\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mfinal_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-778056ca37eb>\u001b[0m in \u001b[0;36mprocess_image\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mmin_line_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mmax_line_gap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mhough_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhough_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mROI_masked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_line_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_line_gap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# Apply the lines to the original image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-60-537fd4445830>\u001b[0m in \u001b[0;36mhough_lines\u001b[0;34m(img, rho, theta, threshold, min_line_len, max_line_gap)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHoughLinesP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminLineLength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_line_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxLineGap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_line_gap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0mline_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     \u001b[0mdraw_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mline_img\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-60-537fd4445830>\u001b[0m in \u001b[0;36mdraw_lines\u001b[0;34m(img, lines, color, thickness)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;31m## Lets group into left and right lane\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mslope\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m.1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mslope\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;31m# Right lane since image is inverted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mgr_slopes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m                 \u001b[0mright_coordinates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0mright_coordinates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gr_slopes' is not defined"
     ]
    }
   ],
   "source": [
    "global gl_slopes\n",
    "gl_slopes = []\n",
    "global gr_slopes\n",
    "gr_slopes = []\n",
    "image = mpimg.imread('test_images/whiteCarLaneSwitch.jpg')\n",
    "\n",
    "print(\"average_left, left_b, left_top_x, bottom_left, top_left\")\n",
    "final_image = process_image(image)\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(final_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test it on Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_left, left_b, left_top_x, bottom_left, top_left\n",
      "8\n",
      "[MoviePy] >>>> Building video test_videos_output/solidWhiteRight.mp4\n",
      "[MoviePy] Writing video test_videos_output/solidWhiteRight.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 11/222 [00:00<00:02, 102.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "21\n",
      "29\n",
      "36\n",
      "39\n",
      "42\n",
      "44\n",
      "47\n",
      "50\n",
      "54\n",
      "58\n",
      "62\n",
      "69\n",
      "77\n",
      "85\n",
      "90\n",
      "94\n",
      "97\n",
      "101\n",
      "105\n",
      "110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 33/222 [00:00<00:01, 104.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114\n",
      "122\n",
      "127\n",
      "136\n",
      "143\n",
      "154\n",
      "161\n",
      "164\n",
      "166\n",
      "169\n",
      "172\n",
      "177\n",
      "182\n",
      "189\n",
      "194\n",
      "201\n",
      "209\n",
      "217\n",
      "224\n",
      "228\n",
      "231\n",
      "234"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 52/222 [00:00<00:01, 87.18it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "237\n",
      "241\n",
      "246\n",
      "252\n",
      "257\n",
      "263\n",
      "271\n",
      "278\n",
      "288\n",
      "295\n",
      "299\n",
      "302\n",
      "305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 67/222 [00:00<00:02, 71.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309\n",
      "315\n",
      "321\n",
      "328\n",
      "334\n",
      "344\n",
      "351\n",
      "361\n",
      "364\n",
      "367\n",
      "370\n",
      "374\n",
      "378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 74/222 [00:00<00:02, 67.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383\n",
      "388\n",
      "394\n",
      "402\n",
      "409\n",
      "416\n",
      "423\n",
      "431\n",
      "434\n",
      "438\n",
      "442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▋      | 81/222 [00:01<00:02, 66.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|███▉      | 88/222 [00:01<00:02, 61.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "452\n",
      "458\n",
      "462\n",
      "466\n",
      "473\n",
      "478\n",
      "486\n",
      "493\n",
      "496\n",
      "499\n",
      "503\n",
      "507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 103/222 [00:01<00:01, 64.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "515\n",
      "521\n",
      "530\n",
      "538\n",
      "546\n",
      "554\n",
      "560\n",
      "562\n",
      "565\n",
      "568\n",
      "574\n",
      "579\n",
      "584\n",
      "591\n",
      "599"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 119/222 [00:01<00:01, 68.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "607\n",
      "614\n",
      "621\n",
      "629\n",
      "633\n",
      "638\n",
      "641\n",
      "643\n",
      "647\n",
      "652\n",
      "657\n",
      "663\n",
      "670\n",
      "676\n",
      "683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 136/222 [00:01<00:01, 72.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690\n",
      "693\n",
      "696\n",
      "700\n",
      "703\n",
      "708\n",
      "715\n",
      "720\n",
      "725\n",
      "732\n",
      "740\n",
      "747\n",
      "755\n",
      "758\n",
      "761\n",
      "765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 152/222 [00:02<00:00, 72.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "769\n",
      "773\n",
      "779\n",
      "786\n",
      "791\n",
      "799\n",
      "807\n",
      "814\n",
      "821\n",
      "824\n",
      "828\n",
      "832\n",
      "836\n",
      "840\n",
      "846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 168/222 [00:02<00:00, 73.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "851\n",
      "857\n",
      "865\n",
      "872\n",
      "881\n",
      "887\n",
      "891\n",
      "893\n",
      "897\n",
      "901\n",
      "906\n",
      "910\n",
      "915\n",
      "922\n",
      "929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 176/222 [00:02<00:00, 70.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "937\n",
      "945\n",
      "954\n",
      "957\n",
      "961\n",
      "963\n",
      "967\n",
      "971\n",
      "976\n",
      "981\n",
      "987\n",
      "994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 184/222 [00:02<00:00, 68.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1002\n",
      "1010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▋ | 192/222 [00:02<00:00, 69.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1015\n",
      "1017\n",
      "1022\n",
      "1026\n",
      "1030\n",
      "1034\n",
      "1039\n",
      "1045\n",
      "1051\n",
      "1057\n",
      "1065\n",
      "1078\n",
      "1085\n",
      "1088\n",
      "1091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 208/222 [00:02<00:00, 72.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1095\n",
      "1099\n",
      "1103\n",
      "1109\n",
      "1116\n",
      "1123\n",
      "1129\n",
      "1136\n",
      "1145\n",
      "1153\n",
      "1155\n",
      "1158\n",
      "1161\n",
      "1165\n",
      "1170\n",
      "1174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 221/222 [00:03<00:00, 73.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1180\n",
      "1186\n",
      "1193\n",
      "1200\n",
      "1207\n",
      "1213\n",
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos_output/solidWhiteRight.mp4 \n",
      "\n",
      "CPU times: user 3.58 s, sys: 683 ms, total: 4.26 s\n",
      "Wall time: 3.42 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/solidWhiteRight.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global gl_slopes\n",
    "gl_slopes = []\n",
    "gr_slopes = []\n",
    "\n",
    "white_output = 'test_videos_output/solidWhiteRight.mp4'\n",
    "clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\")\n",
    "print(\"average_left, left_b, left_top_x, bottom_left, top_left\")\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
